# Prompt

[参考文献：ChatGPT的前生: Prompting思想](https://zhuanlan.zhihu.com/p/608139212)

## 由 预训练-微调 到 Prompt

1. 基于 **预训练-微调** 的策略可以尽可能多地利用各种形式的数据来抽取共性特征，让模型针对特定任务的学习负担减小。
2. 基于 **预训练-微调** 的策略需要根据任务类型设置针对性的微调方式，非常不经济实惠，于是可以采取组件化的策略，将预训练的模型分成组件，通过冻结部分组件、插入新组件的方式加快训练的效率。这样一些相似类型的任务可以共用组件、也可以加快微调效率。
3. 基于 **Adapter Module** 的 **预训练-微调** 策略，在模型某些层中加入不同任务的 Adapter Module (例如 LoRa)，在训练和推理时激活对应的 Adapter Module ，其他任务的 Adapter Module 直接忽略。

以上是关于 **预训练-微调** 策略对于 LLM 的进化路径，本质上还是需要人为设置任务对模型进行指定微调，同一个 LLM 里面实现不同功能实际上还是不同任务模型在分别工作，有没有方法可以建造统一的 LLM 可以自动划分不同任务，答案是使用 **Prompting** 策略。

**Prompting可以做到模糊任务的界限不需要人为对任务进行划分，相反，任务的描述会作为输入的一部分直接输入预训练模型。这其实就是为什么Prompting范式是”通往真正大一统语言模型的关键一步“**



## 提出

Prompting 方法最初是在2020年和 GPT-3 一同提出来的。Prompting 范式认为预训练模型本身就可以完成很多任务，只需要在输入的时候对模型进行**引导(又称：提供context)**即可。怎么引导呢？其实很简单，最开始的 Prompting 版本只需要用自然语言将任务本身进行描述，将任务变为 **填空**(针对双向模型BERT)或者 **生成** (针对自回归模型GPT)的任务即可。举几个简单的例子：

- 文本情绪分类任务：任务本身的目的是任意输入一段文本，预测对应的情绪（正面、负面、中性）。经典的预训练-微调范式下的做法是：将在预训练模型的基础上增加分类器模块并使用特定任务数据进行微调。在遇到输入 `Today is a sunny day` 时，模型输出 `positive` 。而在 Prompting 范式下，我们可以将如下文字直接输入没有经过微调的模型: `Today is a sunny day, i am feeling [MASK] ==> [MASK] is happy`，再将 `happy` 映射为 `positive` 就很容易了。
- 机器翻译任务：任务本身的目的是输入一种语言的一段文本，模型生成另一种语言的同义句。在Prompting 范式下，我们可以将如下文字输入模型： `Translate to English: '今天是个大晴天' ==> Model output 'Today is a sunny day'`。

从上面的例子中我们很容易看出 Prompting 范式有如下特点： **无需特定领域的数据进行训练就可以用于各项NLP任务，并且无需在模型参数上做任何调整** 。 Prompting 的成功证明了在模型和训练数据量大到一定程度时，模型本身就更接近百科全书，而 Prompting 就是将百科全书里的知识金矿挖掘出来的各种钥匙。



## Prompting 方式分类

- Prefix Prompt (NLG) 手工设计，例如上文文本情绪分类任务。
- Cloze Prompt (NLU) 手工设计，例如上文机器翻译任务。
- Prefix Tuning 自动设计

![img](https://pic2.zhimg.com/80/v2-e820c3598183de8d32dfd21e0bb78cd1_720w.webp)

## 总结

**预训练-Prompt** VS **预训练-微调** ：

1. 效果相近，但训练参数少 1000 倍。
2. 模型越大， Prompt 效果越好。
3. 具有非常强大的 zero-shot 和 few-shot 能力。

Prompting技术突破了对任务的常规定义，使得复合任务的实现成为可能（也就是研究人员常说的”zero-shot"）。大家可以回想一下，日常生活中大多数“任务”都不是常规NLP中一个个分门别类的子任务，因此Prompting这种无视任务本身的能力才是它演化出ChatGPT的根本。

